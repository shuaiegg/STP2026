#!/usr/bin/env python3
"""
GEO Content Audit Script

Analyzes markdown content for GEO (Generative Engine Optimization) readiness.
Checks AI extractability, structure, and citation potential.

Usage:
    python geo-audit.py content.md
    python geo-audit.py content.md --brand "Scale to Top"
    python geo-audit.py content.md --json
"""

import argparse
import json
import re
import sys
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Optional


@dataclass
class AuditResult:
    """Audit result with score and details."""
    passed: bool
    score: int
    max_score: int
    issues: list[str]
    suggestions: list[str]
    details: dict


def count_words(text: str) -> int:
    """Count words, handling both CJK and Latin text."""
    # Count CJK characters
    cjk_chars = len(re.findall(r'[\u4e00-\u9fff\u3400-\u4dbf]', text))
    # Count Latin words
    latin_text = re.sub(r'[\u4e00-\u9fff\u3400-\u4dbf]', ' ', text)
    latin_words = len(latin_text.split())
    return cjk_chars + latin_words


def get_first_paragraph(content: str) -> str:
    """Extract first paragraph after any frontmatter."""
    # Remove frontmatter
    content = re.sub(r'^---.*?---\s*', '', content, flags=re.DOTALL)
    # Remove H1
    content = re.sub(r'^#\s+.*?\n', '', content)
    # Get first paragraph
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip() and not p.startswith('#')]
    return paragraphs[0] if paragraphs else ""


def audit_direct_answer(content: str) -> tuple[int, list[str], list[str]]:
    """Check if content has a clear direct answer in the first paragraph."""
    score = 0
    issues = []
    suggestions = []

    first_para = get_first_paragraph(content)
    word_count = count_words(first_para)

    # Check length (ideal: 30-60 words/chars)
    if word_count <= 60:
        score += 15
    elif word_count <= 100:
        score += 10
        suggestions.append(f"é¦–æ®µ {word_count} å­—/è¯ï¼Œå»ºè®®ç²¾ç®€è‡³ 60 ä»¥å†…ä¾¿äº AI æå–")
    else:
        score += 5
        issues.append(f"é¦–æ®µè¿‡é•¿ï¼ˆ{word_count} å­—/è¯ï¼‰ï¼ŒAI éš¾ä»¥å¿«é€Ÿæå–æ ¸å¿ƒç­”æ¡ˆ")

    # Check for definition pattern ("X is/æ˜¯...")
    has_definition = bool(re.search(r'(æ˜¯|ä¸º|æŒ‡|means|is|refers to|defined as)', first_para))
    if has_definition:
        score += 5
    else:
        suggestions.append("é¦–æ®µå»ºè®®ä½¿ç”¨ã€ŒX æ˜¯...ã€æˆ–ã€ŒX refers to...ã€çš„å®šä¹‰å¥å¼")

    return score, issues, suggestions


def audit_heading_structure(content: str) -> tuple[int, list[str], list[str], dict]:
    """Check heading hierarchy and structure."""
    score = 0
    issues = []
    suggestions = []

    h1_matches = re.findall(r'^#\s+(.+)$', content, re.MULTILINE)
    h2_matches = re.findall(r'^##\s+(.+)$', content, re.MULTILINE)
    h3_matches = re.findall(r'^###\s+(.+)$', content, re.MULTILINE)

    details = {
        "h1_count": len(h1_matches),
        "h2_count": len(h2_matches),
        "h3_count": len(h3_matches),
        "h2_titles": h2_matches[:5],  # First 5 for reference
    }

    # H1 check
    if len(h1_matches) == 1:
        score += 5
    elif len(h1_matches) == 0:
        issues.append("ç¼ºå°‘ H1 æ ‡é¢˜")
    else:
        issues.append(f"å­˜åœ¨ {len(h1_matches)} ä¸ª H1 æ ‡é¢˜ï¼Œåº”åªæœ‰ 1 ä¸ª")

    # H2 check (ideal: 3-7)
    if 3 <= len(h2_matches) <= 7:
        score += 10
    elif len(h2_matches) < 3:
        score += 5
        suggestions.append(f"H2 æ ‡é¢˜æ•°é‡åå°‘ï¼ˆ{len(h2_matches)}ï¼‰ï¼Œå»ºè®® 3-7 ä¸ªä¸»è¦ç« èŠ‚")
    else:
        score += 8
        suggestions.append(f"H2 æ ‡é¢˜æ•°é‡è¾ƒå¤šï¼ˆ{len(h2_matches)}ï¼‰ï¼Œå†…å®¹å¯èƒ½éœ€è¦é‡ç»„")

    # Question-format H2s (good for FAQ/AEO)
    question_h2s = [h for h in h2_matches if re.search(r'[?ï¼Ÿ]|^(What|How|Why|When|Which|æ˜¯ä»€ä¹ˆ|ä¸ºä»€ä¹ˆ|å¦‚ä½•|æ€ä¹ˆ)', h)]
    if question_h2s:
        score += 5
        details["question_h2s"] = len(question_h2s)

    return score, issues, suggestions, details


def audit_lists_and_tables(content: str) -> tuple[int, list[str], list[str], dict]:
    """Check for structured content elements."""
    score = 0
    issues = []
    suggestions = []

    # Bullet/numbered lists
    list_items = re.findall(r'^[\s]*[-*+]\s+.+$|^\d+\.\s+.+$', content, re.MULTILINE)
    has_lists = len(list_items) > 0

    # Tables
    tables = re.findall(r'\|.+\|', content)
    has_tables = len(tables) > 2  # At least header + separator + 1 row

    # Code blocks
    code_blocks = re.findall(r'```[\s\S]*?```', content)

    details = {
        "list_items": len(list_items),
        "has_tables": has_tables,
        "code_blocks": len(code_blocks),
    }

    if has_lists:
        score += 5
    else:
        suggestions.append("å»ºè®®æ·»åŠ åˆ—è¡¨æ¥ç»„ç»‡è¦ç‚¹ï¼Œå¢å¼ºå¯æ‰«ææ€§å’Œ AI æå–æ€§")

    if has_tables:
        score += 5
    else:
        suggestions.append("å¯¹æ¯”ç±»å†…å®¹å»ºè®®ä½¿ç”¨è¡¨æ ¼å±•ç¤º")

    return score, issues, suggestions, details


def audit_brand_binding(content: str, brand: Optional[str] = None) -> tuple[int, list[str], list[str]]:
    """Check for brand entity binding."""
    score = 0
    issues = []
    suggestions = []

    if not brand:
        return score, issues, suggestions

    # Count brand mentions
    brand_pattern = re.escape(brand)
    mentions = len(re.findall(brand_pattern, content, re.IGNORECASE))

    if mentions >= 3:
        score += 10
    elif mentions >= 1:
        score += 5
        suggestions.append(f"å“ç‰Œã€Œ{brand}ã€ä»…å‡ºç° {mentions} æ¬¡ï¼Œå»ºè®®åœ¨æ–¹æ³•è®º/æ¡†æ¶å¤„è‡ªç„¶ç»‘å®š")
    else:
        issues.append(f"å†…å®¹ç¼ºå°‘å“ç‰Œã€Œ{brand}ã€ç»‘å®šï¼Œéš¾ä»¥è¢« AI å½’å› å¼•ç”¨")

    return score, issues, suggestions


def audit_cta(content: str) -> tuple[int, list[str], list[str]]:
    """Check for appropriate CTAs."""
    score = 0
    issues = []
    suggestions = []

    # Low-friction CTA patterns
    cta_patterns = [
        r'ä¸‹è½½|Download',
        r'è·å–|Get',
        r'å…è´¹|Free',
        r'æ¨¡æ¿|Template',
        r'Checklist|æ¸…å•',
        r'æŒ‡å—|Guide',
        r'å·¥å…·|Tool',
        r'ç«‹å³|Now',
        r'å¼€å§‹|Start',
        r'è¯•ç”¨|Try',
    ]

    has_cta = any(re.search(p, content, re.IGNORECASE) for p in cta_patterns)

    if has_cta:
        score += 5
    else:
        suggestions.append("å»ºè®®æ·»åŠ ä½æ‘©æ“¦ CTAï¼ˆå¦‚ï¼šæ¨¡æ¿ä¸‹è½½ã€Checklistã€å…è´¹å·¥å…·ç­‰ï¼‰")

    return score, issues, suggestions


def audit_internal_links(content: str) -> tuple[int, list[str], list[str], dict]:
    """Check internal linking."""
    score = 0
    issues = []
    suggestions = []

    # Markdown links
    links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', content)
    internal_links = [l for l in links if not l[1].startswith(('http://', 'https://', 'mailto:'))]
    external_links = [l for l in links if l[1].startswith(('http://', 'https://'))]

    details = {
        "internal_links": len(internal_links),
        "external_links": len(external_links),
    }

    # Internal links (ideal: 3-5)
    if len(internal_links) >= 3:
        score += 5
    elif len(internal_links) >= 1:
        score += 3
        suggestions.append(f"å†…é“¾æ•°é‡åå°‘ï¼ˆ{len(internal_links)}ï¼‰ï¼Œå»ºè®® 3-5 ä¸ªç›¸å…³å†…é“¾")
    else:
        suggestions.append("ç¼ºå°‘å†…é“¾ï¼Œå»ºè®®æ·»åŠ  3-5 ä¸ªç›¸å…³æ–‡ç« é“¾æ¥")

    return score, issues, suggestions, details


def audit_eeat_signals(content: str) -> tuple[int, list[str], list[str]]:
    """Check for E-E-A-T signals."""
    score = 0
    issues = []
    suggestions = []

    # Experience signals ("æˆ‘ä»¬å‘ç°", "In our experience", etc.)
    experience_patterns = [
        r'æˆ‘ä»¬å‘ç°|æˆ‘ä»¬çš„ç»éªŒ|åœ¨.*å®è·µä¸­',
        r'In our experience|We found|We discovered|After.*projects',
        r'ç»è¿‡.*æµ‹è¯•|é€šè¿‡.*éªŒè¯',
    ]
    has_experience = any(re.search(p, content, re.IGNORECASE) for p in experience_patterns)

    # Data/statistics
    has_data = bool(re.search(r'\d+%|\d+\s*[å€xÃ—]|\$[\d,]+|[\d,]+\s*(ç”¨æˆ·|users|å®¢æˆ·|customers)', content))

    # Citations/sources
    has_citations = bool(re.search(r'æ ¹æ®|According to|ç ”ç©¶è¡¨æ˜|æ•°æ®æ˜¾ç¤º|Source:|æ¥æº:', content))

    if has_experience:
        score += 5
    else:
        suggestions.append("å»ºè®®æ·»åŠ ç¬¬ä¸€æ‰‹ç»éªŒè¡¨è¿°ï¼ˆå¦‚ï¼šã€Œæˆ‘ä»¬åœ¨ X é¡¹ç›®ä¸­å‘ç°...ã€ï¼‰")

    if has_data:
        score += 5
    else:
        suggestions.append("å»ºè®®æ·»åŠ å…·ä½“æ•°æ®æˆ–ç»Ÿè®¡æ”¯æ’‘è§‚ç‚¹")

    if has_citations:
        score += 5
    else:
        suggestions.append("å»ºè®®æ·»åŠ æƒå¨æ¥æºå¼•ç”¨å¢å¼ºå¯ä¿¡åº¦")

    return score, issues, suggestions


def audit_content(content: str, brand: Optional[str] = None) -> AuditResult:
    """Run full GEO audit on content."""
    total_score = 0
    max_score = 100
    all_issues = []
    all_suggestions = []
    all_details = {}

    # 1. Direct Answer (20 points)
    score, issues, suggestions = audit_direct_answer(content)
    total_score += score
    all_issues.extend(issues)
    all_suggestions.extend(suggestions)

    # 2. Heading Structure (20 points)
    score, issues, suggestions, details = audit_heading_structure(content)
    total_score += score
    all_issues.extend(issues)
    all_suggestions.extend(suggestions)
    all_details["structure"] = details

    # 3. Lists and Tables (10 points)
    score, issues, suggestions, details = audit_lists_and_tables(content)
    total_score += score
    all_issues.extend(issues)
    all_suggestions.extend(suggestions)
    all_details["elements"] = details

    # 4. Brand Binding (10 points)
    score, issues, suggestions = audit_brand_binding(content, brand)
    total_score += score
    all_issues.extend(issues)
    all_suggestions.extend(suggestions)

    # 5. CTA (5 points)
    score, issues, suggestions = audit_cta(content)
    total_score += score
    all_issues.extend(issues)
    all_suggestions.extend(suggestions)

    # 6. Internal Links (5 points)
    score, issues, suggestions, details = audit_internal_links(content)
    total_score += score
    all_issues.extend(issues)
    all_suggestions.extend(suggestions)
    all_details["links"] = details

    # 7. E-E-A-T Signals (15 points)
    score, issues, suggestions = audit_eeat_signals(content)
    total_score += score
    all_issues.extend(issues)
    all_suggestions.extend(suggestions)

    # Normalize to 100
    # Current max is ~75, scale up
    normalized_score = min(100, int(total_score * 100 / 75))

    return AuditResult(
        passed=normalized_score >= 70,
        score=normalized_score,
        max_score=max_score,
        issues=all_issues,
        suggestions=all_suggestions,
        details=all_details,
    )


def print_report(result: AuditResult, verbose: bool = True):
    """Print human-readable audit report."""
    status = "âœ… PASSED" if result.passed else "âŒ NEEDS IMPROVEMENT"
    print(f"\n{'='*50}")
    print(f"GEO Content Audit Report")
    print(f"{'='*50}")
    print(f"\nScore: {result.score}/{result.max_score} {status}")

    if result.issues:
        print(f"\nğŸš¨ Issues ({len(result.issues)}):")
        for issue in result.issues:
            print(f"  â€¢ {issue}")

    if result.suggestions and verbose:
        print(f"\nğŸ’¡ Suggestions ({len(result.suggestions)}):")
        for suggestion in result.suggestions:
            print(f"  â€¢ {suggestion}")

    if verbose and result.details:
        print(f"\nğŸ“Š Details:")
        if "structure" in result.details:
            s = result.details["structure"]
            print(f"  â€¢ H1: {s['h1_count']}, H2: {s['h2_count']}, H3: {s['h3_count']}")
        if "elements" in result.details:
            e = result.details["elements"]
            print(f"  â€¢ Lists: {e['list_items']} items, Tables: {e['has_tables']}, Code blocks: {e['code_blocks']}")
        if "links" in result.details:
            l = result.details["links"]
            print(f"  â€¢ Internal links: {l['internal_links']}, External links: {l['external_links']}")

    print(f"\n{'='*50}\n")


def main():
    parser = argparse.ArgumentParser(description="GEO Content Audit Tool")
    parser.add_argument("file", help="Markdown file to audit")
    parser.add_argument("--brand", help="Brand name to check for binding")
    parser.add_argument("--json", action="store_true", help="Output as JSON")
    parser.add_argument("--quiet", action="store_true", help="Only show score and issues")

    args = parser.parse_args()

    file_path = Path(args.file)
    if not file_path.exists():
        print(f"Error: File not found: {args.file}", file=sys.stderr)
        sys.exit(1)

    content = file_path.read_text(encoding="utf-8")
    result = audit_content(content, brand=args.brand)

    if args.json:
        print(json.dumps(asdict(result), indent=2, ensure_ascii=False))
    else:
        print_report(result, verbose=not args.quiet)

    # Exit with non-zero if audit failed
    sys.exit(0 if result.passed else 1)


if __name__ == "__main__":
    main()
